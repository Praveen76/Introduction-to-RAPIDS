{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen76/Introduction-to-RAPIDS/blob/main/Introduction_to_RAPIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n"
      ],
      "metadata": {
        "id": "XNTY8ezN6JZH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solid-upset"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* load, simulate, split data, and check dimensions\n",
        "* convert numpy data to DMatrix format\n",
        "* set the parameters and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "e8newvEJqhW0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd-0UJIFtYAm"
      },
      "source": [
        "While the world’s data doubles each year, CPU computing has hit a brick wall with the end of Moore’s law. For the same reasons, scientific computing and deep learning has turned to NVIDIA GPU acceleration, data analytics and machine learning where GPU acceleration is ideal.\n",
        "\n",
        "NVIDIA created RAPIDS, an open source data analytics and machine learning acceleration platform that leverages GPUs to accelerate computations.\n",
        "\n",
        "<br>\n",
        "<img src='https://rapids.ai/images/RAPIDS-logo.png' width=180px>\n",
        "\n",
        "RAPIDS is based on Python, has pandas like and `scikit-learn` like interfaces, is built on `apache arrow` in memory data format, and can scale from 1 to multi GPU to multi nodes. RAPIDS integrates easily into the world’s most popular data science Python based workflows. RAPIDS accelerates data science from data preparation, machine learning, to deep learning. Through Arrow, Spark users can easily move data into the RAPIDS platform for acceleration.\n",
        "\n",
        "In this notebook, the acceleration will be demonstrated by using GPUs with XGBoost in RAPIDS.\n",
        "\n",
        "To know more about RAPIDS, refer [here](https://rapids.ai/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ZyR1qqtr6_"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M8_AST_04_XGBoost_with_RAPIDS_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3600ee25c8e"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-06T21:03:41.067879Z",
          "start_time": "2018-11-06T21:03:40.256654Z"
        },
        "id": "0q38cc34tYA3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the version of the imported libraries"
      ],
      "metadata": {
        "id": "21G24GSZT7-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('numpy Version:', np.__version__)\n",
        "print('pandas Version:', pd.__version__)\n",
        "print('XGBoost Version:', xgb.__version__)"
      ],
      "metadata": {
        "id": "PpgT0XER6hR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you are connected with GPU runtime in colab.\n",
        "\n",
        "> Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_."
      ],
      "metadata": {
        "id": "69-iLFQq5Uo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements for using RAPIDS:**\n",
        "\n",
        "1. NVIDIA Volta™ or higher GPU with compute capability 7.0+\n",
        "\n",
        "2. Ubuntu 20.04 or 22.04, CentOS 7, Rocky Linux 8, or WSL2 on Windows 11\n",
        "\n",
        "3. Recent CUDA version and NVIDIA driver pairs. Check yours with: `nvidia-smi`"
      ],
      "metadata": {
        "id": "n4vgKn1eyUZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check OS:"
      ],
      "metadata": {
        "id": "Dra3nTwEzHNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lsb_release -a"
      ],
      "metadata": {
        "id": "TWv8ErMWy9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r9T5YAYtYA1"
      },
      "source": [
        "Check the CUDA version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-06T21:03:39.490984Z",
          "start_time": "2018-11-06T21:03:39.134608Z"
        },
        "id": "KyzVE0c4tYA2"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-06T21:03:38.237293Z",
          "start_time": "2018-11-06T21:03:37.388285Z"
        },
        "id": "pqx5Cd9RtYAx"
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab's Tesla T4 GPU has compute capability 7.5"
      ],
      "metadata": {
        "id": "R2b050lIz5cq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5OEfaJVtYA4"
      },
      "source": [
        "## Load/Simulate data\n",
        "\n",
        "### Load Data\n",
        "\n",
        "The data can be loaded using `pandas.read_csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for loading data\n",
        "def load_data(filename, n_rows):\n",
        "    if n_rows >= 1e9:    # If number of rows are greater than the threshold value\n",
        "        df = pd.read_csv(filename, nrows=n_rows)\n",
        "    else:\n",
        "        df = pd.read_csv(filename)\n",
        "    return df.values.astype(np.float32)"
      ],
      "metadata": {
        "id": "9wV4GJuKzX8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulate Data\n",
        "\n",
        "The features will be tabular with `n_rows` and `n_columns` in the training dataset, where each value is either of type `np.float32` if the data is numerical or `np.uint8` if the data is categorical. Both numerical and categorical data can also be combined. In this experiment, this combination is not utlised."
      ],
      "metadata": {
        "id": "dzLrlrFUzbCR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WVCA-5BtYA5"
      },
      "outputs": [],
      "source": [
        "# helper function for simulating data\n",
        "def simulate_data(m, n, k=2, numerical=False):\n",
        "    if numerical:\n",
        "        features = np.random.rand(m, n)\n",
        "    else:\n",
        "        features = np.random.randint(2, size=(m, n))\n",
        "    labels = np.random.randint(k, size=m)\n",
        "    return np.c_[labels, features].astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the number of rows, number of columns to be read.\n",
        "\n",
        "If LOAD = False, the data will be simulated."
      ],
      "metadata": {
        "id": "1v05pQWr3qf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iKMHOAftYA6"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "LOAD = False\n",
        "n_rows = int(1e5)\n",
        "n_columns = int(100)\n",
        "n_categories = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending on the 'LOAD' boolean value, either load or simulate the data."
      ],
      "metadata": {
        "id": "D5ghnvzL35Q7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rChZ0tBtYA7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if LOAD:\n",
        "    dataset = load_data('/tmp', n_rows)\n",
        "else:\n",
        "    dataset = simulate_data(n_rows, n_columns, n_categories)\n",
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few rows of the dataset\n",
        "dataset[0:2, :]"
      ],
      "metadata": {
        "id": "qbArrDoX8o7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMyO8h8DtYA8"
      },
      "source": [
        "### Split Data\n",
        "\n",
        "Split the dataset into a 80% training dataset and a 20% test dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# identify shape and indices\n",
        "n_rows, n_columns = dataset.shape\n",
        "train_size = 0.80\n",
        "train_index = int(n_rows * train_size)\n",
        "\n",
        "print(\"number of rows is equal to\", n_rows)\n",
        "print(\"number of columns is equal to\", n_columns)\n",
        "print(\"The train index is equal to\", train_index)"
      ],
      "metadata": {
        "id": "_bJ4HP9b-V5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the data into features and target"
      ],
      "metadata": {
        "id": "YWjDwtyvRSdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split X, y\n",
        "X, y = dataset[:, 1:], dataset[:, 0]\n",
        "del dataset"
      ],
      "metadata": {
        "id": "QOm3VDrVRMzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split train data\n",
        "X_train, y_train = X[:train_index, :], y[:train_index]"
      ],
      "metadata": {
        "id": "mBMTB1anRizH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzv2avKZtYA8"
      },
      "outputs": [],
      "source": [
        "# split test data\n",
        "X_test, y_test = X[train_index:, :], y[train_index:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq-a0J3htYA8"
      },
      "source": [
        "### Check Dimensions\n",
        "\n",
        "Check the dimensions and proportions of the training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check dimensions\n",
        "print('X_train: ', X_train.shape, X_train.dtype, 'y_train: ', y_train.shape, y_train.dtype)\n",
        "print('X_test', X_test.shape, X_test.dtype, 'y_test: ', y_test.shape, y_test.dtype)"
      ],
      "metadata": {
        "id": "a00DqP-duV9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuYlxDGctYA9"
      },
      "outputs": [],
      "source": [
        "# check the proportions\n",
        "total = X_train.shape[0] + X_test.shape[0]\n",
        "\n",
        "print('X_train proportion:', X_train.shape[0] / total)\n",
        "print('X_test proportion:', X_test.shape[0] / total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WXKZU8xtYA9"
      },
      "source": [
        "## Convert NumPy data to DMatrix format\n",
        "\n",
        "The data is simulated and formatted as NumPy arrays, next step is to convert this to a `DMatrix` object that XGBoost can work with. Instantiate an object of the `xgboost.DMatrix` by passing in the feature matrix as the first argument followed by the label vector using the `label=` keyword argument. To learn more about XGBoost's support for data structures other than NumPy arrays, see the documentation for the Data Interface [here](https://xgboost.readthedocs.io/en/latest/python/python_intro.html#data-interface)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-06T21:03:55.278322Z",
          "start_time": "2018-11-06T21:03:54.059643Z"
        },
        "id": "YbnlHRwytYA9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71YsoJa4tYA-"
      },
      "source": [
        "## Set Parameters\n",
        "\n",
        "Before running XGBoost, we must set three types of parameters:\n",
        "\n",
        "* **General parameters** relate to which booster is being used to do boosting, commonly tree or linear model\n",
        "\n",
        "* **Booster parameters** depend on which booster is chosen\n",
        "\n",
        "* **Learning task parameters** decide on the learning scenario. For example, regression tasks may use different parameters with ranking tasks.\n",
        "\n",
        "For more information on the configurable parameters within the XGBoost module, see the documentation [here](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate params\n",
        "params = {}"
      ],
      "metadata": {
        "id": "qnbJk6rHvhm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# general params\n",
        "general_params = {'silent': 1}\n",
        "params.update(general_params)"
      ],
      "metadata": {
        "id": "mM4afIBAvk0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# booster params\n",
        "n_gpus = 2           # no. of GPUs\n",
        "booster_params = {}"
      ],
      "metadata": {
        "id": "mDVMWJaMvoTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if n_gpus != 0:\n",
        "    booster_params['tree_method'] = 'hist'\n",
        "    booster_params['n_gpus'] = n_gpus\n",
        "params.update(booster_params)"
      ],
      "metadata": {
        "id": "C72fnfSI9E15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-06T21:03:57.443698Z",
          "start_time": "2018-11-06T21:03:57.438288Z"
        },
        "id": "ro-GhKk0tYA-"
      },
      "outputs": [],
      "source": [
        "# learning task params\n",
        "learning_task_params = {'eval_metric': 'auc', 'objective': 'binary:logistic'}\n",
        "params.update(learning_task_params)\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8th_WOztYA-"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "Use the `xgb.train` function and pass in the parameters, training dataset, the number of boosting iterations, and the list of items to be evaluated during training.\n",
        "\n",
        "For more information on the parameters that can be passed into `xgb.train`, check out the documentation [here](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpdfO5_3tYA-"
      },
      "outputs": [],
      "source": [
        "# model training settings\n",
        "evallist = [(dtest, 'test'), (dtrain, 'train')]\n",
        "num_round = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-06T21:04:50.201308Z",
          "start_time": "2018-11-06T21:04:00.363740Z"
        },
        "id": "ox0sK4yGtYA-"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "bst = xgb.train(params, dtrain, num_round, evallist)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References"
      ],
      "metadata": {
        "id": "s1nIg2NGwA0i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25iM7lXstYA_"
      },
      "source": [
        "* [Open Source Website](http://rapids.ai)\n",
        "* [GitHub](https://github.com/rapidsai/)\n",
        "* [Press Release](https://nvidianews.nvidia.com/news/nvidia-introduces-rapids-open-source-gpu-acceleration-platform-for-large-scale-data-analytics-and-machine-learning)\n",
        "* [NVIDIA Blog](https://blogs.nvidia.com/blog/2018/10/10/rapids-data-science-open-source-community/)\n",
        "* [Developer Blog](https://devblogs.nvidia.com/gpu-accelerated-analytics-rapids/)\n",
        "* [NVIDIA Data Science Webpage](https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFNLB7O4utb3"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_38KV9uluveS"
      },
      "outputs": [],
      "source": [
        "# @title Select the FALSE statement: { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\",\"RAPIDS is an open source data analytics and ML acceleration platform that leverages GPUs to accelerate computations\",\"RAPIDS is based on Python, has pandas like and scikit-learn like interfaces\",\"RAPIDS is built on apache spark in memory data format, and can scale from 1 to multi GPU to multi nodes\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVj6KRihwhPy"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7Wx_ufawlf8"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Fbfkz82w5BI"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RauzHTwWw8PW"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHVmS408w_Si"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T-LbsTp6xCy3"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}